{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwiczenia2-rozdzial2-zad1",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOME1x9XJLAoYmV1DwxPqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gembuspol/uczenieMaszynowe/blob/main/cwiczenia2_rozdzial2_zad1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yEXEZuwFGbb",
        "outputId": "3ccae867-f1c1-4b52-ef1f-757deae32c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jgXZzZ5jFTy8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create RNN architecture\n",
        "learning_rate = 0.0001\n",
        "seq_len = 50\n",
        "max_epochs = 25\n",
        "hidden_dim = 100\n",
        "output_dim = 1\n",
        "bptt_truncate = 5 # backprop through time --> lasts 5 iterations\n",
        "min_clip_val = -10\n",
        "max_clip_val = 10"
      ],
      "metadata": {
        "id": "gkIh0NR5FWw3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "5wFBKBTNFad3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X, Y, U, V, W):\n",
        "    loss = 0.0\n",
        "    for i in range(Y.shape[0]):\n",
        "        x, y = X[i], Y[i]\n",
        "        prev_activation = np.zeros((hidden_dim, 1)) # value of previous activation\n",
        "        for timestep in range(seq_len):\n",
        "            new_input = np.zeros(x.shape) # forward pass, done for each step in the sequence\n",
        "            new_input[timestep] = x[timestep] # define a single input for that timestep\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_activation)\n",
        "            _sum = mulu + mulw\n",
        "            activation = sigmoid(_sum)\n",
        "            mulv = np.dot(V, activation)\n",
        "            prev_activation = activation\n",
        "        # calculate and add loss per record\n",
        "        loss_per_record = float((y - mulv)**2/2)\n",
        "        loss += loss_per_record\n",
        "    # calculate loss after first Y pass\n",
        "    return loss, activation"
      ],
      "metadata": {
        "id": "R-KX3WU4FbfQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes x values and the weights matrices\n",
        "# returns layer dictionary, final weights (mulu, mulw, mulv)\n",
        "def calc_layers(x, U, V, W, prev_activation):\n",
        "    layers = []\n",
        "    for timestep in range(seq_len):\n",
        "        new_input = np.zeros(x.shape)\n",
        "        new_input[timestep] = x[timestep]\n",
        "        mulu = np.dot(U, new_input)\n",
        "        mulw = np.dot(W, prev_activation)\n",
        "        _sum = mulw + mulu\n",
        "        activation = sigmoid(_sum)\n",
        "        mulv = np.dot(V, activation)\n",
        "        layers.append({'activation': activation, 'prev_activation': prev_activation})\n",
        "        prev_activation = activation\n",
        " \n",
        "    return layers, mulu, mulw, mulv"
      ],
      "metadata": {
        "id": "Or34fhTuFfNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(x, U, V, W, dmulv, mulu, mulw, layers):\n",
        "    dU = np.zeros(U.shape)\n",
        "    dV = np.zeros(V.shape)\n",
        "    dW = np.zeros(W.shape)\n",
        "   \n",
        "    dU_t = np.zeros(U.shape)\n",
        "    dV_t = np.zeros(V.shape)\n",
        "    dW_t = np.zeros(W.shape)\n",
        "   \n",
        "    dU_i = np.zeros(U.shape)\n",
        "    dW_i = np.zeros(W.shape)\n",
        "   \n",
        "    _sum = mulu + mulw\n",
        "    dsv = np.dot(np.transpose(V), dmulv)\n",
        "   \n",
        "    def get_previous_activation_differential(_sum, ds, W):\n",
        "        d_sum = _sum * (1 - _sum) * ds\n",
        "        dmulw = d_sum * np.ones_like(ds)\n",
        "        return np.dot(np.transpose(W), dmulw)\n",
        "   \n",
        "    for timestep in range(seq_len):\n",
        "        dV_t = np.dot(dmulv, np.transpose(layers[timestep]['activation']))\n",
        "        ds = dsv\n",
        "        dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "       \n",
        "        for _ in range(timestep-1, max(-1, timestep-bptt_truncate-1), -1):\n",
        "            ds = dsv + dprev_activation\n",
        "            dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "            dW_i = np.dot(W, layers[timestep]['prev_activation'])\n",
        "           \n",
        "            new_input = np.zeros(x.shape)\n",
        "            new_input[timestep] = x[timestep]\n",
        "            dU_i = np.dot(U, new_input)\n",
        "           \n",
        "            dU_t += dU_i\n",
        "            dW_t += dW_i\n",
        "           \n",
        "        dU += dU_t\n",
        "        dV += dV_t\n",
        "        dW += dW_t\n",
        "       \n",
        "        # take care of possible exploding gradients\n",
        "        if dU.max() > max_clip_val:\n",
        "            dU[dU > max_clip_val] = max_clip_val\n",
        "        if dV.max() > max_clip_val:\n",
        "            dV[dV > max_clip_val] = max_clip_val\n",
        "        if dW.max() > max_clip_val:\n",
        "            dW[dW > max_clip_val] = max_clip_val\n",
        "       \n",
        "        if dU.min() < min_clip_val:\n",
        "            dU[dU < min_clip_val] = min_clip_val\n",
        "        if dV.min() < min_clip_val:\n",
        "            dV[dV < min_clip_val] = min_clip_val\n",
        "        if dW.min() < min_clip_val:\n",
        "            dW[dW < min_clip_val] = min_clip_val\n",
        "       \n",
        "    return dU, dV, dW"
      ],
      "metadata": {
        "id": "nrObSAv3HR5E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "def train(U, V, W, X, Y, X_validation, Y_validation):\n",
        "    for epoch in range(max_epochs):\n",
        "        # calculate initial loss, ie what the output is given a random set of weights\n",
        "        loss, prev_activation = calculate_loss(X, Y, U, V, W)\n",
        " \n",
        "        # check validation loss\n",
        "        val_loss, _ = calculate_loss(X_validation, Y_validation, U, V, W)\n",
        "       \n",
        "        print(f'Epoch: {epoch+1}, Loss: {loss}, Validation Loss: {val_loss}')\n",
        " \n",
        "        # train model/forward pass\n",
        "        for i in range(Y.shape[0]):\n",
        "            x, y = X[i], Y[i]\n",
        "            layers = []\n",
        "            prev_activation = np.zeros((hidden_dim, 1))\n",
        "           \n",
        "            layers, mulu, mulw, mulv = calc_layers(x, U, V, W, prev_activation)\n",
        "               \n",
        "            # difference of the prediction\n",
        "            dmulv = mulv - y\n",
        "            dU, dV, dW = backprop(x, U, V, W, dmulv, mulu, mulw, layers)\n",
        "           \n",
        "            # update weights\n",
        "            U -= learning_rate * dU\n",
        "            V -= learning_rate * dV\n",
        "            W -= learning_rate * dW\n",
        "    return U, V, W"
      ],
      "metadata": {
        "id": "xoPfUG1KHTfs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pque5_cHZN8",
        "outputId": "5aed5a7e-2b5a-4091-a07a-53e2f4ff9ef0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=ada222fd1db2bbf35cd2114a3f95df8b0a76510be68c0f8f707fa81811f3c2f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        " \n",
        "from sklearn.metrics import mean_squared_error\n",
        " \n"
      ],
      "metadata": {
        "id": "8WPOTC8tHdJj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sin_wave = np.array([math.cos(x) * math.sin(x/2) * 3 + 20 for x in range(200)])\n",
        "# training data\n",
        "X = []\n",
        "Y = []\n",
        "num_records = len(sin_wave) - seq_len # 150\n",
        " \n",
        "# X entries are 50 data points\n",
        "# Y entries are the 51st data point\n",
        "for i in range(num_records-50):\n",
        "    X.append(sin_wave[i:i+seq_len])\n",
        "    Y.append(sin_wave[i+seq_len])\n",
        " \n",
        "X = np.expand_dims(np.array(X), axis=2) # 100 x 50 x 1\n",
        "Y = np.expand_dims(np.array(Y), axis=1) # 100 x 1\n",
        " \n",
        "# validation data\n",
        "X_validation = []\n",
        "Y_validation = []\n",
        "for i in range(num_records-seq_len, num_records):\n",
        "    X_validation.append(sin_wave[i:i+seq_len])\n",
        "    Y_validation.append(sin_wave[i+seq_len])\n",
        " \n",
        "X_validation = np.expand_dims(np.array(X_validation), axis=2)\n",
        "Y_validation = np.expand_dims(np.array(Y_validation), axis=1)"
      ],
      "metadata": {
        "id": "sw_9q1wjH42O"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(12161)\n",
        "U = np.random.uniform(0, 1, (hidden_dim, seq_len)) # weights from input to hidden layer\n",
        "V = np.random.uniform(0, 1, (output_dim, hidden_dim)) # weights from hidden to output layer\n",
        "W = np.random.uniform(0, 1, (hidden_dim, hidden_dim)) # recurrent weights for layer (RNN weigts)"
      ],
      "metadata": {
        "id": "qHosMXOZH97f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U, V, W = train(U, V, W, X, Y, X_validation, Y_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PO236GICQ6",
        "outputId": "2f4d1afa-1a2f-4bc8-a61a-660a11f8eb62"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 49470.273132960596, Validation Loss: 24739.228844743764\n",
            "Epoch: 2, Loss: 23051.36708346985, Validation Loss: 11528.510680549969\n",
            "Epoch: 3, Loss: 6632.461033968846, Validation Loss: 3317.7925163510695\n",
            "Epoch: 4, Loss: 302.9574537490719, Validation Loss: 151.84274014922224\n",
            "Epoch: 5, Loss: 113.92266878608163, Validation Loss: 57.09589318506066\n",
            "Epoch: 6, Loss: 1460.353361765408, Validation Loss: 729.586014617528\n",
            "Epoch: 7, Loss: 261.6230664929877, Validation Loss: 130.71195413782178\n",
            "Epoch: 8, Loss: 109.92398364653037, Validation Loss: 55.06768297746987\n",
            "Epoch: 9, Loss: 110.13599296978042, Validation Loss: 55.18648627700214\n",
            "Epoch: 10, Loss: 110.14184559153863, Validation Loss: 55.18970759653623\n",
            "Epoch: 11, Loss: 110.15134563696913, Validation Loss: 55.19458427849348\n",
            "Epoch: 12, Loss: 110.14552106559242, Validation Loss: 55.19155391735442\n",
            "Epoch: 13, Loss: 110.1855161295049, Validation Loss: 55.21207272930332\n",
            "Epoch: 14, Loss: 110.06828555874203, Validation Loss: 55.15191870754874\n",
            "Epoch: 15, Loss: 110.10746909051485, Validation Loss: 55.17169981702787\n",
            "Epoch: 16, Loss: 110.08105570947562, Validation Loss: 55.15832421279862\n",
            "Epoch: 17, Loss: 110.07011130178495, Validation Loss: 55.15301920834192\n",
            "Epoch: 18, Loss: 110.06428479532967, Validation Loss: 55.14996524954586\n",
            "Epoch: 19, Loss: 110.07320234028515, Validation Loss: 55.154625238397436\n",
            "Epoch: 20, Loss: 110.04687938341532, Validation Loss: 55.141223767029764\n",
            "Epoch: 21, Loss: 110.04627460399715, Validation Loss: 55.14079599051909\n",
            "Epoch: 22, Loss: 110.03429333151064, Validation Loss: 55.134720274012146\n",
            "Epoch: 23, Loss: 110.04400651406021, Validation Loss: 55.139691605020076\n",
            "Epoch: 24, Loss: 109.99290987419198, Validation Loss: 55.112936050492905\n",
            "Epoch: 25, Loss: 110.00645570578351, Validation Loss: 55.12021682814834\n"
          ]
        }
      ]
    }
  ]
}