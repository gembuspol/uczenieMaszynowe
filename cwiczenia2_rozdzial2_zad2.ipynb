{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwiczenia2-rozdzial2-zad2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY2zS6mVbVvwowdC3rNbAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gembuspol/uczenieMaszynowe/blob/main/cwiczenia2_rozdzial2_zad2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yEXEZuwFGbb",
        "outputId": "3ccae867-f1c1-4b52-ef1f-757deae32c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jgXZzZ5jFTy8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create RNN architecture\n",
        "learning_rate = 0.0001\n",
        "seq_len = 50\n",
        "max_epochs = 25\n",
        "hidden_dim = 100\n",
        "output_dim = 1\n",
        "bptt_truncate = 5 # backprop through time --> lasts 5 iterations\n",
        "min_clip_val = -10\n",
        "max_clip_val = 10"
      ],
      "metadata": {
        "id": "gkIh0NR5FWw3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "5wFBKBTNFad3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X, Y, U, V, W):\n",
        "    loss = 0.0\n",
        "    for i in range(Y.shape[0]):\n",
        "        x, y = X[i], Y[i]\n",
        "        prev_activation = np.zeros((hidden_dim, 1)) # value of previous activation\n",
        "        for timestep in range(seq_len):\n",
        "            new_input = np.zeros(x.shape) # forward pass, done for each step in the sequence\n",
        "            new_input[timestep] = x[timestep] # define a single input for that timestep\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_activation)\n",
        "            _sum = mulu + mulw\n",
        "            activation = sigmoid(_sum)\n",
        "            mulv = np.dot(V, activation)\n",
        "            prev_activation = activation\n",
        "        # calculate and add loss per record\n",
        "        loss_per_record = float((y - mulv)**2/2)\n",
        "        loss += loss_per_record\n",
        "    # calculate loss after first Y pass\n",
        "    return loss, activation"
      ],
      "metadata": {
        "id": "R-KX3WU4FbfQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes x values and the weights matrices\n",
        "# returns layer dictionary, final weights (mulu, mulw, mulv)\n",
        "def calc_layers(x, U, V, W, prev_activation):\n",
        "    layers = []\n",
        "    for timestep in range(seq_len):\n",
        "        new_input = np.zeros(x.shape)\n",
        "        new_input[timestep] = x[timestep]\n",
        "        mulu = np.dot(U, new_input)\n",
        "        mulw = np.dot(W, prev_activation)\n",
        "        _sum = mulw + mulu\n",
        "        activation = sigmoid(_sum)\n",
        "        mulv = np.dot(V, activation)\n",
        "        layers.append({'activation': activation, 'prev_activation': prev_activation})\n",
        "        prev_activation = activation\n",
        " \n",
        "    return layers, mulu, mulw, mulv"
      ],
      "metadata": {
        "id": "Or34fhTuFfNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(x, U, V, W, dmulv, mulu, mulw, layers):\n",
        "    dU = np.zeros(U.shape)\n",
        "    dV = np.zeros(V.shape)\n",
        "    dW = np.zeros(W.shape)\n",
        "   \n",
        "    dU_t = np.zeros(U.shape)\n",
        "    dV_t = np.zeros(V.shape)\n",
        "    dW_t = np.zeros(W.shape)\n",
        "   \n",
        "    dU_i = np.zeros(U.shape)\n",
        "    dW_i = np.zeros(W.shape)\n",
        "   \n",
        "    _sum = mulu + mulw\n",
        "    dsv = np.dot(np.transpose(V), dmulv)\n",
        "   \n",
        "    def get_previous_activation_differential(_sum, ds, W):\n",
        "        d_sum = _sum * (1 - _sum) * ds\n",
        "        dmulw = d_sum * np.ones_like(ds)\n",
        "        return np.dot(np.transpose(W), dmulw)\n",
        "   \n",
        "    for timestep in range(seq_len):\n",
        "        dV_t = np.dot(dmulv, np.transpose(layers[timestep]['activation']))\n",
        "        ds = dsv\n",
        "        dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "       \n",
        "        for _ in range(timestep-1, max(-1, timestep-bptt_truncate-1), -1):\n",
        "            ds = dsv + dprev_activation\n",
        "            dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "            dW_i = np.dot(W, layers[timestep]['prev_activation'])\n",
        "           \n",
        "            new_input = np.zeros(x.shape)\n",
        "            new_input[timestep] = x[timestep]\n",
        "            dU_i = np.dot(U, new_input)\n",
        "           \n",
        "            dU_t += dU_i\n",
        "            dW_t += dW_i\n",
        "           \n",
        "        dU += dU_t\n",
        "        dV += dV_t\n",
        "        dW += dW_t\n",
        "       \n",
        "        # take care of possible exploding gradients\n",
        "        if dU.max() > max_clip_val:\n",
        "            dU[dU > max_clip_val] = max_clip_val\n",
        "        if dV.max() > max_clip_val:\n",
        "            dV[dV > max_clip_val] = max_clip_val\n",
        "        if dW.max() > max_clip_val:\n",
        "            dW[dW > max_clip_val] = max_clip_val\n",
        "       \n",
        "        if dU.min() < min_clip_val:\n",
        "            dU[dU < min_clip_val] = min_clip_val\n",
        "        if dV.min() < min_clip_val:\n",
        "            dV[dV < min_clip_val] = min_clip_val\n",
        "        if dW.min() < min_clip_val:\n",
        "            dW[dW < min_clip_val] = min_clip_val\n",
        "       \n",
        "    return dU, dV, dW"
      ],
      "metadata": {
        "id": "nrObSAv3HR5E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "def train(U, V, W, X, Y, X_validation, Y_validation):\n",
        "    for epoch in range(max_epochs):\n",
        "        # calculate initial loss, ie what the output is given a random set of weights\n",
        "        loss, prev_activation = calculate_loss(X, Y, U, V, W)\n",
        " \n",
        "        # check validation loss\n",
        "        val_loss, _ = calculate_loss(X_validation, Y_validation, U, V, W)\n",
        "       \n",
        "        print(f'Epoch: {epoch+1}, Loss: {loss}, Validation Loss: {val_loss}')\n",
        " \n",
        "        # train model/forward pass\n",
        "        for i in range(Y.shape[0]):\n",
        "            x, y = X[i], Y[i]\n",
        "            layers = []\n",
        "            prev_activation = np.zeros((hidden_dim, 1))\n",
        "           \n",
        "            layers, mulu, mulw, mulv = calc_layers(x, U, V, W, prev_activation)\n",
        "               \n",
        "            # difference of the prediction\n",
        "            dmulv = mulv - y\n",
        "            dU, dV, dW = backprop(x, U, V, W, dmulv, mulu, mulw, layers)\n",
        "           \n",
        "            # update weights\n",
        "            U -= learning_rate * dU\n",
        "            V -= learning_rate * dV\n",
        "            W -= learning_rate * dW\n",
        "    return U, V, W"
      ],
      "metadata": {
        "id": "xoPfUG1KHTfs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pque5_cHZN8",
        "outputId": "5aed5a7e-2b5a-4091-a07a-53e2f4ff9ef0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=ada222fd1db2bbf35cd2114a3f95df8b0a76510be68c0f8f707fa81811f3c2f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        " \n",
        "from sklearn.metrics import mean_squared_error\n",
        " \n"
      ],
      "metadata": {
        "id": "8WPOTC8tHdJj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sin_wave = np.array([math.cos(x) * math.cos(x) * math.sin(x/2) + 1 for x in range(200)])\n",
        "# training data\n",
        "X = []\n",
        "Y = []\n",
        "num_records = len(sin_wave) - seq_len # 150\n",
        " \n",
        "# X entries are 50 data points\n",
        "# Y entries are the 51st data point\n",
        "for i in range(num_records-50):\n",
        "    X.append(sin_wave[i:i+seq_len])\n",
        "    Y.append(sin_wave[i+seq_len])\n",
        " \n",
        "X = np.expand_dims(np.array(X), axis=2) # 100 x 50 x 1\n",
        "Y = np.expand_dims(np.array(Y), axis=1) # 100 x 1\n",
        " \n",
        "# validation data\n",
        "X_validation = []\n",
        "Y_validation = []\n",
        "for i in range(num_records-seq_len, num_records):\n",
        "    X_validation.append(sin_wave[i:i+seq_len])\n",
        "    Y_validation.append(sin_wave[i+seq_len])\n",
        " \n",
        "X_validation = np.expand_dims(np.array(X_validation), axis=2)\n",
        "Y_validation = np.expand_dims(np.array(Y_validation), axis=1)"
      ],
      "metadata": {
        "id": "sw_9q1wjH42O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(12161)\n",
        "U = np.random.uniform(0, 1, (hidden_dim, seq_len)) # weights from input to hidden layer\n",
        "V = np.random.uniform(0, 1, (output_dim, hidden_dim)) # weights from hidden to output layer\n",
        "W = np.random.uniform(0, 1, (hidden_dim, hidden_dim)) # recurrent weights for layer (RNN weigts)"
      ],
      "metadata": {
        "id": "qHosMXOZH97f"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U, V, W = train(U, V, W, X, Y, X_validation, Y_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PO236GICQ6",
        "outputId": "63fdf7c6-c81f-4b33-a3c7-9c91835183ff"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 127131.94415365474, Validation Loss: 63568.35520586108\n",
            "Epoch: 2, Loss: 81709.22741426648, Validation Loss: 40856.524463450354\n",
            "Epoch: 3, Loss: 46286.51067477474, Validation Loss: 23144.69372098799\n",
            "Epoch: 4, Loss: 20863.792805206605, Validation Loss: 10432.862414057803\n",
            "Epoch: 5, Loss: 5433.971318725523, Validation Loss: 2717.482876961641\n",
            "Epoch: 6, Loss: 10.387490633621772, Validation Loss: 5.205182948714873\n",
            "Epoch: 7, Loss: 8.635638657284147, Validation Loss: 4.321118368600739\n",
            "Epoch: 8, Loss: 9.055137004600937, Validation Loss: 4.527035825832315\n",
            "Epoch: 9, Loss: 8.637393426210236, Validation Loss: 4.321012207098442\n",
            "Epoch: 10, Loss: 9.1173440213541, Validation Loss: 4.557787388125156\n",
            "Epoch: 11, Loss: 9.220044338246613, Validation Loss: 4.608892822022541\n",
            "Epoch: 12, Loss: 8.64961585614711, Validation Loss: 4.327631945739814\n",
            "Epoch: 13, Loss: 8.913441255836576, Validation Loss: 4.456964746557631\n",
            "Epoch: 14, Loss: 8.619630611711752, Validation Loss: 4.312382968076762\n",
            "Epoch: 15, Loss: 8.619090585059729, Validation Loss: 4.31594417600323\n",
            "Epoch: 16, Loss: 9.384585095962533, Validation Loss: 4.690538368493212\n",
            "Epoch: 17, Loss: 8.731407670708366, Validation Loss: 4.367367039817906\n",
            "Epoch: 18, Loss: 8.649149644317843, Validation Loss: 4.32675165670956\n",
            "Epoch: 19, Loss: 8.574225536367504, Validation Loss: 4.290647876583027\n",
            "Epoch: 20, Loss: 8.986997849795042, Validation Loss: 4.492845872210217\n",
            "Epoch: 21, Loss: 8.586789954574634, Validation Loss: 4.296347766727276\n",
            "Epoch: 22, Loss: 9.41346625948637, Validation Loss: 4.704722089952401\n",
            "Epoch: 23, Loss: 9.02323865098424, Validation Loss: 4.510849344014214\n",
            "Epoch: 24, Loss: 8.82147120995588, Validation Loss: 4.411473233101262\n",
            "Epoch: 25, Loss: 8.720404873549366, Validation Loss: 4.361753183727601\n"
          ]
        }
      ]
    }
  ]
}