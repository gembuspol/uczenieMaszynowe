{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwiczenia2-rozdzial2-zad3",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8vCEAbnbQ0vrMfLF2Z6bb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gembuspol/uczenieMaszynowe/blob/main/cwiczenia2_rozdzial2_zad3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yEXEZuwFGbb",
        "outputId": "3ccae867-f1c1-4b52-ef1f-757deae32c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jgXZzZ5jFTy8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create RNN architecture\n",
        "learning_rate = 0.0001\n",
        "seq_len = 50\n",
        "max_epochs = 25\n",
        "hidden_dim = 100\n",
        "output_dim = 1\n",
        "bptt_truncate = 5 # backprop through time --> lasts 5 iterations\n",
        "min_clip_val = -10\n",
        "max_clip_val = 10"
      ],
      "metadata": {
        "id": "gkIh0NR5FWw3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))"
      ],
      "metadata": {
        "id": "5wFBKBTNFad3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X, Y, U, V, W):\n",
        "    loss = 0.0\n",
        "    for i in range(Y.shape[0]):\n",
        "        x, y = X[i], Y[i]\n",
        "        prev_activation = np.zeros((hidden_dim, 1)) # value of previous activation\n",
        "        for timestep in range(seq_len):\n",
        "            new_input = np.zeros(x.shape) # forward pass, done for each step in the sequence\n",
        "            new_input[timestep] = x[timestep] # define a single input for that timestep\n",
        "            mulu = np.dot(U, new_input)\n",
        "            mulw = np.dot(W, prev_activation)\n",
        "            _sum = mulu + mulw\n",
        "            activation = sigmoid(_sum)\n",
        "            mulv = np.dot(V, activation)\n",
        "            prev_activation = activation\n",
        "        # calculate and add loss per record\n",
        "        loss_per_record = float((y - mulv)**2/2)\n",
        "        loss += loss_per_record\n",
        "    # calculate loss after first Y pass\n",
        "    return loss, activation"
      ],
      "metadata": {
        "id": "R-KX3WU4FbfQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes x values and the weights matrices\n",
        "# returns layer dictionary, final weights (mulu, mulw, mulv)\n",
        "def calc_layers(x, U, V, W, prev_activation):\n",
        "    layers = []\n",
        "    for timestep in range(seq_len):\n",
        "        new_input = np.zeros(x.shape)\n",
        "        new_input[timestep] = x[timestep]\n",
        "        mulu = np.dot(U, new_input)\n",
        "        mulw = np.dot(W, prev_activation)\n",
        "        _sum = mulw + mulu\n",
        "        activation = sigmoid(_sum)\n",
        "        mulv = np.dot(V, activation)\n",
        "        layers.append({'activation': activation, 'prev_activation': prev_activation})\n",
        "        prev_activation = activation\n",
        " \n",
        "    return layers, mulu, mulw, mulv"
      ],
      "metadata": {
        "id": "Or34fhTuFfNp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backprop(x, U, V, W, dmulv, mulu, mulw, layers):\n",
        "    dU = np.zeros(U.shape)\n",
        "    dV = np.zeros(V.shape)\n",
        "    dW = np.zeros(W.shape)\n",
        "   \n",
        "    dU_t = np.zeros(U.shape)\n",
        "    dV_t = np.zeros(V.shape)\n",
        "    dW_t = np.zeros(W.shape)\n",
        "   \n",
        "    dU_i = np.zeros(U.shape)\n",
        "    dW_i = np.zeros(W.shape)\n",
        "   \n",
        "    _sum = mulu + mulw\n",
        "    dsv = np.dot(np.transpose(V), dmulv)\n",
        "   \n",
        "    def get_previous_activation_differential(_sum, ds, W):\n",
        "        d_sum = _sum * (1 - _sum) * ds\n",
        "        dmulw = d_sum * np.ones_like(ds)\n",
        "        return np.dot(np.transpose(W), dmulw)\n",
        "   \n",
        "    for timestep in range(seq_len):\n",
        "        dV_t = np.dot(dmulv, np.transpose(layers[timestep]['activation']))\n",
        "        ds = dsv\n",
        "        dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "       \n",
        "        for _ in range(timestep-1, max(-1, timestep-bptt_truncate-1), -1):\n",
        "            ds = dsv + dprev_activation\n",
        "            dprev_activation = get_previous_activation_differential(_sum, ds, W)\n",
        "            dW_i = np.dot(W, layers[timestep]['prev_activation'])\n",
        "           \n",
        "            new_input = np.zeros(x.shape)\n",
        "            new_input[timestep] = x[timestep]\n",
        "            dU_i = np.dot(U, new_input)\n",
        "           \n",
        "            dU_t += dU_i\n",
        "            dW_t += dW_i\n",
        "           \n",
        "        dU += dU_t\n",
        "        dV += dV_t\n",
        "        dW += dW_t\n",
        "       \n",
        "        # take care of possible exploding gradients\n",
        "        if dU.max() > max_clip_val:\n",
        "            dU[dU > max_clip_val] = max_clip_val\n",
        "        if dV.max() > max_clip_val:\n",
        "            dV[dV > max_clip_val] = max_clip_val\n",
        "        if dW.max() > max_clip_val:\n",
        "            dW[dW > max_clip_val] = max_clip_val\n",
        "       \n",
        "        if dU.min() < min_clip_val:\n",
        "            dU[dU < min_clip_val] = min_clip_val\n",
        "        if dV.min() < min_clip_val:\n",
        "            dV[dV < min_clip_val] = min_clip_val\n",
        "        if dW.min() < min_clip_val:\n",
        "            dW[dW < min_clip_val] = min_clip_val\n",
        "       \n",
        "    return dU, dV, dW"
      ],
      "metadata": {
        "id": "nrObSAv3HR5E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "def train(U, V, W, X, Y, X_validation, Y_validation):\n",
        "    for epoch in range(max_epochs):\n",
        "        # calculate initial loss, ie what the output is given a random set of weights\n",
        "        loss, prev_activation = calculate_loss(X, Y, U, V, W)\n",
        " \n",
        "        # check validation loss\n",
        "        val_loss, _ = calculate_loss(X_validation, Y_validation, U, V, W)\n",
        "       \n",
        "        print(f'Epoch: {epoch+1}, Loss: {loss}, Validation Loss: {val_loss}')\n",
        " \n",
        "        # train model/forward pass\n",
        "        for i in range(Y.shape[0]):\n",
        "            x, y = X[i], Y[i]\n",
        "            layers = []\n",
        "            prev_activation = np.zeros((hidden_dim, 1))\n",
        "           \n",
        "            layers, mulu, mulw, mulv = calc_layers(x, U, V, W, prev_activation)\n",
        "               \n",
        "            # difference of the prediction\n",
        "            dmulv = mulv - y\n",
        "            dU, dV, dW = backprop(x, U, V, W, dmulv, mulu, mulw, layers)\n",
        "           \n",
        "            # update weights\n",
        "            U -= learning_rate * dU\n",
        "            V -= learning_rate * dV\n",
        "            W -= learning_rate * dW\n",
        "    return U, V, W"
      ],
      "metadata": {
        "id": "xoPfUG1KHTfs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pque5_cHZN8",
        "outputId": "5aed5a7e-2b5a-4091-a07a-53e2f4ff9ef0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=ada222fd1db2bbf35cd2114a3f95df8b0a76510be68c0f8f707fa81811f3c2f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        " \n",
        "from sklearn.metrics import mean_squared_error\n",
        " \n"
      ],
      "metadata": {
        "id": "8WPOTC8tHdJj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sin_wave = np.array([math.cos(x) * math.sin(x * 3) + 5 for x in range(200)])\n",
        "# training data\n",
        "X = []\n",
        "Y = []\n",
        "num_records = len(sin_wave) - seq_len # 150\n",
        " \n",
        "# X entries are 50 data points\n",
        "# Y entries are the 51st data point\n",
        "for i in range(num_records-50):\n",
        "    X.append(sin_wave[i:i+seq_len])\n",
        "    Y.append(sin_wave[i+seq_len])\n",
        " \n",
        "X = np.expand_dims(np.array(X), axis=2) # 100 x 50 x 1\n",
        "Y = np.expand_dims(np.array(Y), axis=1) # 100 x 1\n",
        " \n",
        "# validation data\n",
        "X_validation = []\n",
        "Y_validation = []\n",
        "for i in range(num_records-seq_len, num_records):\n",
        "    X_validation.append(sin_wave[i:i+seq_len])\n",
        "    Y_validation.append(sin_wave[i+seq_len])\n",
        " \n",
        "X_validation = np.expand_dims(np.array(X_validation), axis=2)\n",
        "Y_validation = np.expand_dims(np.array(Y_validation), axis=1)"
      ],
      "metadata": {
        "id": "sw_9q1wjH42O"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(12161)\n",
        "U = np.random.uniform(0, 1, (hidden_dim, seq_len)) # weights from input to hidden layer\n",
        "V = np.random.uniform(0, 1, (output_dim, hidden_dim)) # weights from hidden to output layer\n",
        "W = np.random.uniform(0, 1, (hidden_dim, hidden_dim)) # recurrent weights for layer (RNN weigts)"
      ],
      "metadata": {
        "id": "qHosMXOZH97f"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U, V, W = train(U, V, W, X, Y, X_validation, Y_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PO236GICQ6",
        "outputId": "da7d539f-571d-4220-b2f4-03e7bb43c5b2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 107776.61643709529, Validation Loss: 53889.272420632165\n",
            "Epoch: 2, Loss: 66351.79418513914, Validation Loss: 33176.47327758017\n",
            "Epoch: 3, Loss: 34926.971933161, Validation Loss: 17463.67413451712\n",
            "Epoch: 4, Loss: 13502.149394857584, Validation Loss: 6750.874848369388\n",
            "Epoch: 5, Loss: 2076.2900864163475, Validation Loss: 1037.5572930184828\n",
            "Epoch: 6, Loss: 21.785116468278773, Validation Loss: 9.981702499686104\n",
            "Epoch: 7, Loss: 11.984156675324638, Validation Loss: 5.200761293624218\n",
            "Epoch: 8, Loss: 12.03487312688394, Validation Loss: 5.222980093739017\n",
            "Epoch: 9, Loss: 12.008745922135768, Validation Loss: 5.2117204348633335\n",
            "Epoch: 10, Loss: 12.02061962743658, Validation Loss: 5.21730523011527\n",
            "Epoch: 11, Loss: 12.06772258429412, Validation Loss: 5.238419545839341\n",
            "Epoch: 12, Loss: 11.94529852031313, Validation Loss: 5.183676314887971\n",
            "Epoch: 13, Loss: 12.133933118382004, Validation Loss: 5.268800000216918\n",
            "Epoch: 14, Loss: 12.027373112809004, Validation Loss: 5.220009418701615\n",
            "Epoch: 15, Loss: 12.036081727618477, Validation Loss: 5.224009784989653\n",
            "Epoch: 16, Loss: 12.105777769112132, Validation Loss: 5.255482835381101\n",
            "Epoch: 17, Loss: 12.079302052694624, Validation Loss: 5.243438951091188\n",
            "Epoch: 18, Loss: 12.06197299036525, Validation Loss: 5.235416681243814\n",
            "Epoch: 19, Loss: 12.091503052608488, Validation Loss: 5.2497606512956905\n",
            "Epoch: 20, Loss: 12.162367955552986, Validation Loss: 5.282279885313091\n",
            "Epoch: 21, Loss: 11.957571844523983, Validation Loss: 5.189134461818594\n",
            "Epoch: 22, Loss: 11.988049682634744, Validation Loss: 5.202564895130986\n",
            "Epoch: 23, Loss: 11.939206352519925, Validation Loss: 5.181124482885684\n",
            "Epoch: 24, Loss: 11.949514363115444, Validation Loss: 5.184961051638097\n",
            "Epoch: 25, Loss: 12.007740105290962, Validation Loss: 5.212233843389739\n"
          ]
        }
      ]
    }
  ]
}
